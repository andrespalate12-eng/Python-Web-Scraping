{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Web Scraping with Beautiful Soup\n",
    "\n",
    "* * * \n",
    "\n",
    "### Icons used in this notebook\n",
    "üîî **Question**: A quick question to help you understand what's going on.<br>\n",
    "ü•ä **Challenge**: Interactive exercise. We'll work through these in the workshop!<br>\n",
    "‚ö†Ô∏è **Warning**: Heads-up about tricky stuff or common mistakes.<br>\n",
    "üí° **Tip**: How to do something a bit more efficiently or effectively.<br>\n",
    "üé¨ **Demo**: Showing off something more advanced ‚Äì so you know what Python can be used for!<br>\n",
    "\n",
    "### Learning Objectives\n",
    "1. [Reflection: To Scape Or Not To Scrape](#when)\n",
    "2. [Extracting and Parsing HTML](#extract)\n",
    "3. [Scraping the Illinois General Assembly](#scrape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='when'></a>\n",
    "\n",
    "# To Scrape Or Not To Scrape\n",
    "\n",
    "When we'd like to access data from the web, we first have to make sure if the website we are interested in offers a Web API. Platforms like Twitter, Reddit, and the New York Times offer APIs. **Check out D-Lab's [Python Web APIs](https://github.com/dlab-berkeley/Python-Web-APIs) workshop if you want to learn how to use APIs.**\n",
    "\n",
    "However, there are often cases when a Web API does not exist. In these cases, we may have to resort to web scraping, where we extract the underlying HTML from a web page, and directly obtain the information we want. There are several packages in Python we can use to accomplish these tasks. We'll focus two packages: Requests and Beautiful Soup.\n",
    "\n",
    "Our case study will be scraping information on the [state senators of Illinois](http://www.ilga.gov/senate), as well as the [list of bills](http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True) each senator has sponsored. Before we get started, peruse these websites to take a look at their structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Installation\n",
    "\n",
    "We will use two main packages: [Requests](http://docs.python-requests.org/en/latest/user/quickstart/) and [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/). Go ahead and install these packages, if you haven't already:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "La siguiente secci√≥n corresponde a la instalaci√≥n de los paquetes necesarios: requests, beautifulsoup4 y lxml.\n",
    "## Funcion del request\n",
    "\n",
    "* Permite realizar peticiones HTTP de manera sencilla y manejar las respuestas devueltas por un servidor web.\n",
    "* Facilita operaciones como enviar par√°metros, encabezados y autenticaci√≥n en las solicitudes.\n",
    "\n",
    "## Funcion del beautifulsoup4\n",
    "\n",
    "* Se utiliza para extraer y procesar informaci√≥n de p√°ginas web obtenidas mediante una solicitud HTTP.\n",
    "* Permite navegar y buscar de forma intuitiva entre etiquetas, atributos y textos dentro del c√≥digo HTML.\n",
    "\n",
    "## Funcion del lxml\n",
    "\n",
    "* Es una librer√≠a especializada en el procesamiento y manipulaci√≥n de documentos XML y HTML.\n",
    "* Resulta muy eficiente en tareas que requieren analizar, transformar o extraer datos estructurados en forma de √°rbol.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (2.31.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.4.3)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2.5.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from requests) (2025.8.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (4.13.4)\n",
      "Requirement already satisfied: soupsieve>1.2 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (2.7)\n",
      "Requirement already satisfied: typing-extensions>=4.0.0 in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (from beautifulsoup4) (4.14.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll also install the `lxml` package, which helps support some of the parsing that Beautiful Soup performs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\user\\appdata\\local\\programs\\python\\python313\\lib\\site-packages (6.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install lxml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importaci√≥n de librer√≠as\n",
    "\n",
    "En esta secci√≥n se importan las librer√≠as necesarias que ser√°n utilizadas en el script para realizar web scraping, manipulaci√≥n de fechas y control de tiempo en la ejecuci√≥n.\n",
    "\n",
    "- **from bs4 import BeautifulSoup** ‚Üí importa BeautifulSoup, que se usar√° para analizar y extraer informaci√≥n de documentos HTML.  \n",
    "- **from datetime import datetime** ‚Üí permite trabajar con fechas y horas, como obtener la fecha actual o formatear timestamps.  \n",
    "- **import requests** ‚Üí se utiliza para realizar peticiones HTTP y obtener el contenido de p√°ginas web.  \n",
    "- **import time** ‚Üí proporciona funciones para controlar pausas en la ejecuci√≥n del script, por ejemplo usando `time.sleep()`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Import required libraries\n",
    "from bs4 import BeautifulSoup\n",
    "from datetime import datetime\n",
    "import requests\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='extract'></a>\n",
    "\n",
    "# Extracting and Parsing HTML \n",
    "\n",
    "In order to succesfully scrape and analyse HTML, we'll be going through the following 4 steps:\n",
    "1. Make a GET request\n",
    "2. Parse the page with Beautiful Soup\n",
    "3. Search for HTML elements\n",
    "4. Get attributes and text of these elements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Make a GET Request to Obtain a Page's HTML\n",
    "\n",
    "We can use the Requests library to:\n",
    "\n",
    "1. Make a GET request to the page, and\n",
    "2. Read in the webpage's HTML code.\n",
    "\n",
    "The process of making a request and obtaining a result resembles that of the Web API workflow. Now, however, we're making a request directly to the website, and we're going to have to parse the HTML ourselves. This is in contrast to being provided data organized into a more straightforward `JSON` or `XML` output."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": []
   },
   "source": [
    "Este bloque realiza un request HTTP mediante el metodo GET a un sitio web y muestra parte del contenido recibido.  \n",
    "\n",
    "- **req = requests.get(http://www.ilga.gov/senate/default.asp)** ‚Üí Realiza una solicitud HTTP GET a la URL especificada\n",
    "\n",
    "- **src = req.text** ‚Üí Obtiene el contenido de la respuesta del servidor en formato de texto (HTML) \n",
    "\n",
    "- **print(src[:1000])** ‚Üí  Muestra los primeros 1000 caracteres del contenido para ver una vista previa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      "<head id=\"Head1\">\n",
      "    <meta name=\"viewport\" content=\"width=device-width, initial-scale=1.0\" />\n",
      "    <meta http-equiv=\"content-type\" content=\"text/html;charset=utf-8\" />\n",
      "    <meta http-equiv=\"X-UA-Compatible\" content=\"IE=Edge\" />\n",
      "    <meta charset=\"utf-8\" />\n",
      "    <meta charset=\"UTF-8\">\n",
      "    <!-- Meta Description -->\n",
      "    <meta name=\"description\" content=\"Welcome to the official government website of the Illinois General Assembly\">\n",
      "    <meta name=\"contactName\" content=\"Legislative Information System\">\n",
      "    <meta name=\"contactOrganization\" content=\"LIS Staff Services\">\n",
      "    <meta name=\"contactStreetAddress1\" content=\"705 Stratton Office Building\">\n",
      "    <meta name=\"contactCity\" content=\"Springfield\">\n",
      "    <meta name=\"contactZipcode\" content=\"62706\">\n",
      "    <meta name=\"contactNetworkAddress\" content=\"webmaster@ilga.gov\">\n",
      "    <meta name=\"contactPhoneNumber\" content=\"217-782-3944\">\n",
      "    <meta name=\"contactFaxNumber\" content=\"217-524-6059\">\n",
      "    <meta name\n"
     ]
    }
   ],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp')\n",
    "# Read the content of the server‚Äôs response\n",
    "src = req.text\n",
    "# View some output\n",
    "print(src[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Parse the Page with Beautiful Soup\n",
    "\n",
    "Now, we use the `BeautifulSoup` function to parse the reponse into an HTML tree. This returns an object (called a **soup object**) which contains all of the HTML in the original document.\n",
    "\n",
    "If you run into an error about a parser library, make sure you've installed the `lxml` package to provide Beautiful Soup with the necessary parsing tools."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicacion del bloque de codigo ##\n",
    "Este bloque convierte la respuesta obtenida del servidor en un √°rbol HTML utilizando *BeautifulSoup*, lo que facilita navegar y extraer informaci√≥n de la p√°gina de los primeros 1000 caracteres.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en\">\n",
      " <head id=\"Head1\">\n",
      "  <meta content=\"width=device-width, initial-scale=1.0\" name=\"viewport\"/>\n",
      "  <meta content=\"text/html;charset=utf-8\" http-equiv=\"content-type\"/>\n",
      "  <meta content=\"IE=Edge\" http-equiv=\"X-UA-Compatible\"/>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <!-- Meta Description -->\n",
      "  <meta content=\"Welcome to the official government website of the Illinois General Assembly\" name=\"description\"/>\n",
      "  <meta content=\"Legislative Information System\" name=\"contactName\"/>\n",
      "  <meta content=\"LIS Staff Services\" name=\"contactOrganization\"/>\n",
      "  <meta content=\"705 Stratton Office Building\" name=\"contactStreetAddress1\"/>\n",
      "  <meta content=\"Springfield\" name=\"contactCity\"/>\n",
      "  <meta content=\"62706\" name=\"contactZipcode\"/>\n",
      "  <meta content=\"webmaster@ilga.gov\" name=\"contactNetworkAddress\"/>\n",
      "  <meta content=\"217-782-3944\" name=\"contactPhoneNumber\"/>\n",
      "  <meta content=\"217-524-6059\" name=\"contactFaxNumber\"/>\n",
      "  <meta content=\"State Of Illinois\" name=\"originatorJur\n"
     ]
    }
   ],
   "source": [
    "# Parse the response into an HTML tree\n",
    "soup = BeautifulSoup(src, 'lxml')\n",
    "# Take a look\n",
    "print(soup.prettify()[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The output looks pretty similar to the above, but now it's organized in a `soup` object which allows us to more easily traverse the page."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 3: Search for HTML Elements\n",
    "\n",
    "Beautiful Soup has a number of functions to find useful components on a page. Beautiful Soup lets you find elements by their:\n",
    "\n",
    "1. HTML tags\n",
    "2. HTML Attributes\n",
    "3. CSS Selectors\n",
    "\n",
    "Let's search first for **HTML tags**. \n",
    "\n",
    "The function `find_all` searches the `soup` tree to find all the elements with an a particular HTML tag, and returns all of those elements.\n",
    "\n",
    "What does the example below do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "\n",
    "Busca todos los elementos con la etiqueta `<a>` dentro del √°rbol HTML y muestra √∫nicamente los primeros 10 resultados encontrados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[<a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"en\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-us\"></span> English\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"af\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-za\"></span> Afrikaans\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"sq\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-al\"></span> Albanian\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"ar\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-ae\"></span> Arabic\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"hy\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-am\"></span> Armenian\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"az\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-az\"></span> Azerbaijani\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"eu\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-eu\"></span> Basque\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"bn\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-bd\"></span> Bengali\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"bs\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-ba\"></span> Bosnian\n",
      "                            </a>, <a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"ca\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-es\"></span> Catalan\n",
      "                            </a>]\n"
     ]
    }
   ],
   "source": [
    "# Find all elements with a certain tag\n",
    "a_tags = soup.find_all(\"a\")\n",
    "print(a_tags[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because `find_all()` is the most popular method in the Beautiful Soup search API, you can use a shortcut for it. If you treat the BeautifulSoup object as though it were a function, then it‚Äôs the same as calling `find_all()` on that object. \n",
    "\n",
    "These two lines of code are equivalent:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se buscan todos los elementos con la etiqueta `<a>` usando dos formas equivalentes (`soup.find_all(\"a\")` y `soup(\"a\")`) y se imprime el primer elemento obtenido en cada caso. Por ultimo, imprime la cantidad de elementos del primer caso."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"en\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-us\"></span> English\n",
      "                            </a>\n",
      "<a b-0yw6sxot5c=\"\" class=\"dropdown-item\" data-lang=\"en\" href=\"#\">\n",
      "<span b-0yw6sxot5c=\"\" class=\"flag-icon flag-icon-us\"></span> English\n",
      "                            </a>\n"
     ]
    }
   ],
   "source": [
    "a_tags = soup.find_all(\"a\")\n",
    "a_tags_alt = soup(\"a\")\n",
    "print(a_tags[0])\n",
    "print(a_tags_alt[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How many links did we obtain?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "270\n"
     ]
    }
   ],
   "source": [
    "print(len(a_tags))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a lot! Many elements on a page will have the same HTML tag. For instance, if you search for everything with the `a` tag, you're likely to get more hits, many of which you might not want. Remember, the `a` tag defines a hyperlink, so you'll usually find many on any given page.\n",
    "\n",
    "What if we wanted to search for HTML tags with certain attributes, such as particular CSS classes? \n",
    "\n",
    "We can do this by adding an additional argument to the `find_all`. In the example below, we are finding all the `a` tags, and then filtering those with `class_=\"sidemenu\"`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se buscan espec√≠ficamente las etiquetas `<a>` que pertenecen a la clase `sidemenu` dentro del HTML. Primero se usa el codigo `soup(\"a\", class_=\"sidemenu\")` y luego la sintaxis de selectores CSS con `soup.select(\"a.sidemenu\")`. En ambos casos se mostraria solo los primeros 5 resultados encontrados, sin embargo, no encuentra ninguna clase sidemenu por lo que no muestra algun dato y la cantidad aparece en 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get only the 'a' tags in 'sidemenu' class\n",
    "side_menus = soup(\"a\", class_=\"sidemenu\")\n",
    "print(len(side_menus))\n",
    "side_menus[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A more efficient way to search for elements on a website is via a **CSS selector**. For this we have to use a different method called `select()`. Just pass a string into the `.select()` to get all elements with that string as a valid CSS selector.\n",
    "\n",
    "In the example above, we can use `\"a.sidemenu\"` as a CSS selector, which returns all `a` tags with class `sidemenu`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get elements with \"a.sidemenu\" CSS Selector.\n",
    "selected = soup.select(\"a.sidemenu\")\n",
    "selected[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge: Find All\n",
    "\n",
    "Use BeautifulSoup to find all the `a` elements with class `mainmenu`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "En este caso busca la etiqueta `<a>` que pertenecen a la clase `mainmenu` dentro del HTML con la sintaxis de selectores y presentar√≠a los ultimos 5 elementos. Sin embargo, como no encuentra una clase mainmenu, no presenta data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get elements with \"a.mainmenu\" CSS Selector.\n",
    "selected_main = soup.select(\"a.mainmenu\")\n",
    "selected_main[:5]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 4: Get Attributes and Text of Elements\n",
    "\n",
    "Once we identify elements, we want the access information in that element. Usually, this means two things:\n",
    "\n",
    "1. Text\n",
    "2. Attributes\n",
    "\n",
    "Getting the text inside an element is easy. All we have to do is use the `text` member of a `tag` object:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Intenta obtener todos los enlaces `<a>` con la clase `sidemenu` y examinar el primero de ellos. Tambi√©n verifica el tipo de dato de la variable que contiene el primer enlace.  \n",
    "Sin embargo, como la lista no obtiene datos con la clase sidemenu, al intentar acceder a `side_menu_links[0]` se genera un `IndexError`.  \n",
    "Luego, con los comando `first_link.text` y `first_link['href']` nos arroja un `NameError` porque la variable `first_link` no est√° definida, ya que la lista `side_menu_links` estaba vac√≠a en el paso anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      2\u001b[39m side_menu_links = soup.select(\u001b[33m\"\u001b[39m\u001b[33ma.sidemenu\u001b[39m\u001b[33m\"\u001b[39m)   \n\u001b[32m      4\u001b[39m     \u001b[38;5;66;03m# Examine the first link\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m first_link = \u001b[43mside_menu_links\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(first_link)\n\u001b[32m      8\u001b[39m     \u001b[38;5;66;03m# What class is this variable?\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    " # Get all sidemenu links as a list\n",
    "side_menu_links = soup.select(\"a.sidemenu\")   \n",
    "\n",
    "    # Examine the first link\n",
    "first_link = side_menu_links[0]\n",
    "print(first_link)\n",
    "\n",
    "    # What class is this variable?\n",
    "print('Class: ', type(first_link))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's a Beautiful Soup tag! This means it has a `text` member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfirst_link\u001b[49m.text)\n",
      "\u001b[31mNameError\u001b[39m: name 'first_link' is not defined"
     ]
    }
   ],
   "source": [
    "print(first_link.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes we want the value of certain attributes. This is particularly relevant for `a` tags, or links, where the `href` attribute tells us where the link goes.\n",
    "\n",
    "üí° **Tip**: You can access a tag‚Äôs attributes by treating the tag like a dictionary:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'first_link' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[18]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mfirst_link\u001b[49m[\u001b[33m'\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mNameError\u001b[39m: name 'first_link' is not defined"
     ]
    }
   ],
   "source": [
    "print(first_link['href'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Challenge: Extract specific attributes\n",
    "\n",
    "Extract all `href` attributes for each `mainmenu` URL."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se buscan todos los enlaces `<a>` que pertenecen a la clase `mainmenu` y se guardan en la lista `main_menu_links`. Luego se intenta acceder al primer elemento de esa lista y mostrar su atributo `href`.  \n",
    "Como resultado se genera un `IndexError` porque la lista `main_menu_links` est√° vac√≠a, es decir, no se encontraron enlaces con la clase `mainmenu` en el HTML descargado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[15]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get all mainmenu links as a list\u001b[39;00m\n\u001b[32m      2\u001b[39m main_menu_links = soup.select(\u001b[33m\"\u001b[39m\u001b[33ma.mainmenu\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m first_link_menu = \u001b[43mmain_menu_links\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(first_link_menu[\u001b[33m'\u001b[39m\u001b[33mhref\u001b[39m\u001b[33m'\u001b[39m])\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "\n",
    "# Get all mainmenu links as a list\n",
    "main_menu_links = soup.select(\"a.mainmenu\")\n",
    "first_link_menu = main_menu_links[0]\n",
    "print(first_link_menu['href'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='scrape'></a>\n",
    "\n",
    "# Scraping the Illinois General Assembly\n",
    "\n",
    "Believe it or not, those are really the fundamental tools you need to scrape a website. Once you spend more time familiarizing yourself with HTML and CSS, then it's simply a matter of understanding the structure of a particular website and intelligently applying the tools of Beautiful Soup and Python.\n",
    "\n",
    "Let's apply these skills to scrape the [Illinois 98th General Assembly](http://www.ilga.gov/senate/default.asp?GA=98).\n",
    "\n",
    "Specifically, our goal is to scrape information on each senator, including their name, district, and party."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scrape and Soup the Webpage\n",
    "\n",
    "Let's scrape and parse the webpage, using the tools we learned in the previous section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se realiza una solicitud HTTP GET a la p√°gina con el par√°metro `GA=98`, se obtiene el contenido de la respuesta y se convierte en un √°rbol HTML con BeautifulSoup utilizando el parser `lxml`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
    "# Read the content of the server‚Äôs response\n",
    "src = req.text\n",
    "# Soup it\n",
    "soup = BeautifulSoup(src, \"lxml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search for the Table Elements\n",
    "\n",
    "Our goal is to obtain the elements in the table on the webpage. Remember: rows are identified by the `tr` tag. Let's use `find_all` to obtain these elements."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se obtienen todas las filas de tabla (`<tr>`) en el HTML usando dos m√©todos: `find_all(\"tr\")` y el selector CSS `'tr tr tr'`. Luego se imprimen las primeras 5 filas** encontradas.   \n",
    "Sin embargo, como no obtiene dada no tenemos resultados, asi mismo en la longitud con el comando len(rows) podemos verificar que aparece el valor de 0. Por ultimo, al tratar de acceder al tercer valor se genera un `IndexError` ya que la variable `rows` est√° vac√≠a y no contiene ning√∫n elemento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get all table row elements\n",
    "rows = soup.find_all(\"tr\")\n",
    "len(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "‚ö†Ô∏è **Warning**: Keep in mind: `find_all` gets *all* the elements with the `tr` tag. We only want some of them. If we use the 'Inspect' function in Google Chrome and look carefully, then we can use some CSS selectors to get just the rows we're interested in. Specifically, we want the inner rows of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Returns every ‚Äòtr tr tr‚Äô css selector in the page\n",
    "rows = soup.select('tr tr tr')\n",
    "\n",
    "for row in rows[:5]:\n",
    "    print(row, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like we want everything after the first two rows. Let's work with a single row to start, and build our loop from there."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[22]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m example_row = \u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(example_row.prettify())\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "example_row = rows[2]\n",
    "print(example_row.prettify())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's break this row down into its component cells/columns using the `select` method with CSS selectors. Looking closely at the HTML, there are a couple of ways we could do this.\n",
    "\n",
    "* We could identify the cells by their tag `td`.\n",
    "* We could use the the class name `.detail`.\n",
    "* We could combine both and use the selector `td.detail`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se recorren los elementos de una fila de tabla (`example_row`) y se trata de imprimir las celdas que coinciden con distintos selectores:  \n",
    "- `td` selecciona todas las celdas de la fila.  \n",
    "- `.detail` selecciona los elementos que tienen la clase `detail`.  \n",
    "- `td.detail` selecciona espec√≠ficamente las celdas `<td>` con la clase `detail`.  \n",
    "\n",
    "Finalmente, con `assert` se valida que los tres selectores devuelven el mismo resultado.\n",
    "\n",
    "Presentamos como resultado el error `NameError` ya que el `example_row` no logro ser definida por lo mencionado en el anterior bloque de codigo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[23]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m \u001b[43mexample_row\u001b[49m.select(\u001b[33m'\u001b[39m\u001b[33mtd\u001b[39m\u001b[33m'\u001b[39m):\n\u001b[32m      2\u001b[39m     \u001b[38;5;28mprint\u001b[39m(cell)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m()\n",
      "\u001b[31mNameError\u001b[39m: name 'example_row' is not defined"
     ]
    }
   ],
   "source": [
    "for cell in example_row.select('td'):\n",
    "    print(cell)\n",
    "print()\n",
    "\n",
    "for cell in example_row.select('.detail'):\n",
    "    print(cell)\n",
    "print()\n",
    "\n",
    "for cell in example_row.select('td.detail'):\n",
    "    print(cell)\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can confirm that these are all the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[24]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01massert\u001b[39;00m \u001b[43mexample_row\u001b[49m.select(\u001b[33m'\u001b[39m\u001b[33mtd\u001b[39m\u001b[33m'\u001b[39m) == example_row.select(\u001b[33m'\u001b[39m\u001b[33m.detail\u001b[39m\u001b[33m'\u001b[39m) == example_row.select(\u001b[33m'\u001b[39m\u001b[33mtd.detail\u001b[39m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mNameError\u001b[39m: name 'example_row' is not defined"
     ]
    }
   ],
   "source": [
    "assert example_row.select('td') == example_row.select('.detail') == example_row.select('td.detail')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the selector `td.detail` to be as specific as possible."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "En este bloque se busca extraer √∫nicamente las celdas `<td>` de una fila (`example_row`) que tengan la clase `detail`.  \n",
    "Despu√©s, se crea una lista row_data que contiene solo el texto de esas celdas y por ultimo, se pueda acceder a posiciones espec√≠ficas para extraer valores concretos como Name, District y Party.  \n",
    "Como resultado se tienen error del tipo `NameError` por lo antes mencionado con la variable `example_row`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'example_row' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[25]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Select only those 'td' tags with class 'detail' \u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m detail_cells = \u001b[43mexample_row\u001b[49m.select(\u001b[33m'\u001b[39m\u001b[33mtd.detail\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m detail_cells\n",
      "\u001b[31mNameError\u001b[39m: name 'example_row' is not defined"
     ]
    }
   ],
   "source": [
    "# Select only those 'td' tags with class 'detail' \n",
    "detail_cells = example_row.select('td.detail')\n",
    "detail_cells"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most of the time, we're interested in the actual **text** of a website, not its tags. Recall that to get the text of an HTML element, we use the `text` member:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'detail_cells' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[27]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Keep only the text in each of those cells\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m row_data = [cell.text \u001b[38;5;28;01mfor\u001b[39;00m cell \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdetail_cells\u001b[49m]\n\u001b[32m      4\u001b[39m \u001b[38;5;28mprint\u001b[39m(row_data)\n",
      "\u001b[31mNameError\u001b[39m: name 'detail_cells' is not defined"
     ]
    }
   ],
   "source": [
    "# Keep only the text in each of those cells\n",
    "row_data = [cell.text for cell in detail_cells]\n",
    "\n",
    "print(row_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks good! Now we just use our basic Python knowledge to get the elements of this list that we want. Remember, we want the senator's name, their district, and their party."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'row_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[28]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrow_data\u001b[49m[\u001b[32m0\u001b[39m]) \u001b[38;5;66;03m# Name\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(row_data[\u001b[32m3\u001b[39m]) \u001b[38;5;66;03m# District\u001b[39;00m\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(row_data[\u001b[32m4\u001b[39m]) \u001b[38;5;66;03m# Party\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'row_data' is not defined"
     ]
    }
   ],
   "source": [
    "print(row_data[0]) # Name\n",
    "print(row_data[3]) # District\n",
    "print(row_data[4]) # Party"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting Rid of Junk Rows\n",
    "\n",
    "We saw at the beginning that not all of the rows we got actually correspond to a senator. We'll need to do some cleaning before we can proceed forward. Take a look at some examples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Este bloque intenta inspeccionar filas espec√≠ficas de la lista `rows` y luego medir su tama√±o con `len(rows[0])` para distinguir entre filas ‚Äúmalas‚Äù y ‚Äúbuenas‚Äù.  \n",
    "\n",
    "Sin embargo, se produce un `IndexError`al acceder a `rows[0]` porque `rows` est√° vac√≠a (no hay ning√∫n elemento en esa posici√≥n). Por el mismo motivo, la llamada `len(rows[0])` vuelve a fallar e intenta obtener la longitud de un elemento que no existe.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[29]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRow 0:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, \u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mRow 1:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, rows[\u001b[32m1\u001b[39m], \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mLast Row:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m, rows[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "print('Row 0:\\n', rows[0], '\\n')\n",
    "print('Row 1:\\n', rows[1], '\\n')\n",
    "print('Last Row:\\n', rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we write our for loop, we only want it to apply to the relevant rows. So we'll need to filter out the irrelevant rows. The way to do this is to compare some of these to the rows we do want, see how they differ, and then formulate that in a conditional.\n",
    "\n",
    "As you can imagine, there a lot of possible ways to do this, and it'll depend on the website. We'll show some here to give you an idea of how to do this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[30]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Bad rows\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m))\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(rows[\u001b[32m1\u001b[39m]))\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# Good rows\u001b[39;00m\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Bad rows\n",
    "print(len(rows[0]))\n",
    "print(len(rows[1]))\n",
    "\n",
    "# Good rows\n",
    "print(len(rows[2]))\n",
    "print(len(rows[3]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Perhaps good rows have a length of 5. Let's check:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "\n",
    "En este bloque se intenta filtrar las filas \"buenas\" de la lista `rows`.  \n",
    "Primero se crea la lista `good_rows`, que guarda √∫nicamente aquellas filas cuyo tama√±o (`len(row)`) es igual a 5.  \n",
    "\n",
    "Posteriormente, se intenta imprimir algunos elementos de `good_rows`. Sin embargo, se genera un `IndexError` al tratar de imprimir el primer elemento, es decir `good_rows[0]`, ya que la lista `good_rows` est√° vac√≠a.\n",
    "\n",
    "De manera similar, al intentar acceder a `rows[2].select('td.detail')` o a `rows[-1]`, aparece el mismo error `IndexError`: la lista `rows` est√° vac√≠a y no existe ning√∫n elemento en esas posiciones.   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[31]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m good_rows = [row \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m rows \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row) == \u001b[32m5\u001b[39m]\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# Let's check some rows\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mgood_rows\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m, \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(good_rows[-\u001b[32m2\u001b[39m], \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      6\u001b[39m \u001b[38;5;28mprint\u001b[39m(good_rows[-\u001b[32m1\u001b[39m])\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "good_rows = [row for row in rows if len(row) == 5]\n",
    "\n",
    "# Let's check some rows\n",
    "print(good_rows[0], '\\n')\n",
    "print(good_rows[-2], '\\n')\n",
    "print(good_rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found a footer row in our list that we'd like to avoid. Let's try something else:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m.select(\u001b[33m'\u001b[39m\u001b[33mtd.detail\u001b[39m\u001b[33m'\u001b[39m) \n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "rows[2].select('td.detail') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[33]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Bad row\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[43mrows\u001b[49m\u001b[43m[\u001b[49m\u001b[43m-\u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m]\u001b[49m.select(\u001b[33m'\u001b[39m\u001b[33mtd.detail\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Good row\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(rows[\u001b[32m5\u001b[39m].select(\u001b[33m'\u001b[39m\u001b[33mtd.detail\u001b[39m\u001b[33m'\u001b[39m), \u001b[33m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m'\u001b[39m)\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Bad row\n",
    "print(rows[-1].select('td.detail'), '\\n')\n",
    "\n",
    "# Good row\n",
    "print(rows[5].select('td.detail'), '\\n')\n",
    "\n",
    "# How about this?\n",
    "good_rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "print(\"Checking rows...\\n\")\n",
    "print(good_rows[0], '\\n')\n",
    "print(good_rows[-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we found something that worked!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loop it All Together\n",
    "\n",
    "Now that we've seen how to get the data we want from one row, as well as filter out the rows we don't want, let's put it all together into a loop."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "En este bloque se busca procesar las filas v√°lidas (`valid_rows`) de la lista `rows` y almacenar informaci√≥n de cada senador en una lista llamada `members` y al final mostrar los primeros 5 registros. Como la lista `rows` esta vacia desde el inicio, `valid_rows` tambi√©n estar√° vac√≠a y, en consecuencia, `members` quedar√° como una lista vac√≠a []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define storage list\n",
    "members = []\n",
    "\n",
    "# Get rid of junk rows\n",
    "valid_rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "# Loop through all rows\n",
    "for row in valid_rows:\n",
    "    # Select only those 'td' tags with class 'detail'\n",
    "    detail_cells = row.select('td.detail')\n",
    "    # Keep only the text in each of those cells\n",
    "    row_data = [cell.text for cell in detail_cells]\n",
    "    # Collect information\n",
    "    name = row_data[0]\n",
    "    district = int(row_data[3])\n",
    "    party = row_data[4]\n",
    "    # Store in a tuple\n",
    "    senator = (name, district, party)\n",
    "    # Append to list\n",
    "    members.append(senator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Should be 61\n",
    "len(members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take a look at what we have in `members`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(members[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä  Challenge: Get `href` elements pointing to members' bills \n",
    "\n",
    "The code above retrieves information on:  \n",
    "\n",
    "- the senator's name,\n",
    "- their district number,\n",
    "- and their party.\n",
    "\n",
    "We now want to retrieve the URL for each senator's list of bills. Each URL will follow a specific format. \n",
    "\n",
    "The format for the list of bills for a given senator is:\n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?GA=98&MemberID=[MEMBER_ID]&Primary=True`\n",
    "\n",
    "to get something like:\n",
    "\n",
    "`http://www.ilga.gov/senate/SenatorBills.asp?MemberID=1911&GA=98&Primary=True`\n",
    "\n",
    "in which `MEMBER_ID=1911`. \n",
    "\n",
    "You should be able to see that, unfortunately, `MEMBER_ID` is not currently something pulled out in our scraping code.\n",
    "\n",
    "Your initial task is to modify the code above so that we also **retrieve the full URL which points to the corresponding page of primary-sponsored bills**, for each member, and return it along with their name, district, and party.\n",
    "\n",
    "Tips: \n",
    "\n",
    "* To do this, you will want to get the appropriate anchor element (`<a>`) in each legislator's row of the table. You can again use the `.select()` method on the `row` object in the loop to do this ‚Äî similar to the command that finds all of the `td.detail` cells in the row. Remember that we only want the link to the legislator's bills, not the committees or the legislator's profile page.\n",
    "* The anchor elements' HTML will look like `<a href=\"/senate/Senator.asp/...\">Bills</a>`. The string in the `href` attribute contains the **relative** link we are after. You can access an attribute of a BeatifulSoup `Tag` object the same way you access a Python dictionary: `anchor['attributeName']`. See the <a href=\"http://www.crummy.com/software/BeautifulSoup/bs4/doc/#tag\">documentation</a> for more details.\n",
    "* There are a _lot_ of different ways to use BeautifulSoup to get things done. whatever you need to do to pull the `href` out is fine.\n",
    "\n",
    "The code has been partially filled out for you. Fill it in where it says `#YOUR CODE HERE`. Save the path into an object called `full_path`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se hace una petici√≥n HTTP a la p√°gina del Senado y se analiza el contenido con `BeautifulSoup` usando el parser lxml.\n",
    "Se seleccionan todas las filas `<tr>` y se filtran solo aquellas que contienen celdas con clase `td.detail`, que corresponden a los datos de los senadores.  \n",
    "\n",
    "Posteriormente, se recorre las filas y extrae informaci√≥n, para cada fila v√°lida se obtiene los datos: Nombre del senador, N√∫mero de distrito, Partido pol√≠tico, Enlace a los proyectos de ley (Bills), construyendo la URL completa a partir del atributo `href`.\n",
    "\n",
    "Toda la informaci√≥n se guarda en una lista members como tuplas (name, district, party, full_path). Finalmente se pueden inspeccionar los primeros cinco elementos para verificar los datos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Make a GET request\n",
    "req = requests.get('http://www.ilga.gov/senate/default.asp?GA=98')\n",
    "# Read the content of the server‚Äôs response\n",
    "src = req.text\n",
    "# Soup it\n",
    "soup = BeautifulSoup(src, \"lxml\")\n",
    "# Create empty list to store our data\n",
    "members = []\n",
    "# Returns every ‚Äòtr tr tr‚Äô css selector in the page\n",
    "rows = soup.select('tr')\n",
    "# Get rid of junk rows\n",
    "rows = [row for row in rows if row.select('td.detail')]\n",
    "\n",
    "# Loop through all rows\n",
    "for row in rows:\n",
    "    # Select only those 'td' tags with class 'detail'\n",
    "    detail_cells = row.select('td.detail') \n",
    "    # Keep only the text in each of those cells\n",
    "    row_data = [cell.text.strip() for cell in detail_cells]  # strip() limpia espacios extra\n",
    "    #row_data = [cell.text for cell in detail_cells]\n",
    "    # Collect information\n",
    "    name = row_data[0]\n",
    "    district = int(row_data[3])\n",
    "    party = row_data[4]\n",
    "    # YOUR CODE HERE\n",
    "    # Buscar el enlace hacia \"Bills\"\n",
    "    bill_link = row.select_one('a[href*=\"SenatorBills.asp\"]')\n",
    "    if bill_link:\n",
    "        relative_path = bill_link['href']  # extrae el atributo href\n",
    "        full_path = \"http://www.ilga.gov\" + relative_path  # construye el enlace completo\n",
    "    else:\n",
    "        full_path = None  # en caso de que no exista enlace\n",
    "\n",
    "\n",
    "    # Store in a tuple\n",
    "    senator = (name, district, party, full_path)\n",
    "    # Append to list\n",
    "    members.append(senator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Uncomment to test \n",
    "members[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä  Challenge: Modularize Your Code\n",
    "\n",
    "Turn the code above into a function that accepts a URL, scrapes the URL for its senators, and returns a list of tuples containing information about each senator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Este bloque define una funci√≥n modular llamada get_members que realiza scraping de una p√°gina del Senado de Illinois y devuelve la informaci√≥n de cada senador en forma de tuplas.\n",
    "La funci√≥n acepta cualquier URL de la p√°gina del Senado que siga la misma estructura de tablas.\n",
    "Se hace una petici√≥n HTTP a la URL y se analiza el contenido con BeautifulSoup usando el parser lxml. Se seleccionan todas las filas `<tr>` y se filtran solo las que contienen celdas con clase `td.detail`, que corresponden a los datos de los senadores.  \n",
    "\n",
    "Extrae la informaci√≥n de cada senador como en el anterior ejercicio, construyendo la URL completa a partir del atributo `href`. Cada senador se almacena como una tupla (nombre, distrito, partido, full_path) y se agrega a la lista members.  \n",
    "Al final, la funci√≥n devuelve la lista con todos los senadores extra√≠dos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "def get_members(url):\n",
    "    # Hacer la petici√≥n HTTP\n",
    "    req = requests.get(url)\n",
    "    src = req.text\n",
    "    soup = BeautifulSoup(src, \"lxml\")\n",
    "\n",
    "    members = []\n",
    "\n",
    "    # Seleccionar todas las filas <tr> que contengan celdas con clase 'detail'\n",
    "    rows = [row for row in soup.select('tr') if row.select('td.detail')]\n",
    "\n",
    "    # Recorrer las filas v√°lidas\n",
    "    for row in rows:\n",
    "        detail_cells = row.select('td.detail')\n",
    "        row_data = [cell.text.strip() for cell in detail_cells]\n",
    "\n",
    "        name = row_data[0]\n",
    "        district = int(row_data[3])\n",
    "        party = row_data[4]\n",
    "\n",
    "        # Obtener el enlace a los Bills\n",
    "        bill_link = row.select_one('a[href*=\"SenatorBills.asp\"]')\n",
    "        if bill_link:\n",
    "            full_path = \"http://www.ilga.gov\" + bill_link['href']\n",
    "        else:\n",
    "            full_path = None\n",
    "\n",
    "        # Guardar la informaci√≥n en la lista\n",
    "        members.append((name, district, party, full_path))\n",
    "\n",
    "    return members\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Test your code\n",
    "url = 'http://www.ilga.gov/senate/default.asp?GA=98'\n",
    "senate_members = get_members(url)\n",
    "len(senate_members)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ü•ä Take-home Challenge: Writing a Scraper Function\n",
    "\n",
    "We want to scrape the webpages corresponding to bills sponsored by each bills.\n",
    "\n",
    "Write a function called `get_bills(url)` to parse a given bills URL. This will involve:\n",
    "\n",
    "  - requesting the URL using the <a href=\"http://docs.python-requests.org/en/latest/\">`requests`</a> library\n",
    "  - using the features of the `BeautifulSoup` library to find all of the `<td>` elements with the class `billlist`\n",
    "  - return a _list_ of tuples, each with:\n",
    "      - description (2nd column)\n",
    "      - chamber (S or H) (3rd column)\n",
    "      - the last action (4th column)\n",
    "      - the last action date (5th column)\n",
    "      \n",
    "This function has been partially completed. Fill in the rest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "En el codigo agregado se selecciona todas las filas `<tr>` y dentro de ellas solo las celdas `<td>` con clase `billlist`, que contienen los datos de cada bill.  \n",
    "Extrae los distintos datos para almacenar cada bill como una tupla (bill_id, description, chamber, last_action, last_action_date) y la agrega a la lista `bills`. Como en la variable `senate_members` no tenia data, en este caso tendre un error del tipo `IndexError` ya que trata de obtener un elemento en una posici√≥n vacia."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_bills(url):\n",
    "    src = requests.get(url).text\n",
    "    soup = BeautifulSoup(src)\n",
    "    rows = soup.select('tr')\n",
    "    bills = []\n",
    "    for row in rows:\n",
    "        # YOUR CODE HERE\n",
    "        cells = row.select('td.billlist')  # Solo las celdas con clase billlist\n",
    "        if len(cells) < 5:\n",
    "            continue  # Ignorar filas incompletas\n",
    "\n",
    "        bill_id = cells[0].text.strip()           # 1ra columna\n",
    "        description = cells[1].text.strip()       # 2da columna\n",
    "        chamber = cells[2].text.strip()           # 3ra columna\n",
    "        last_action = cells[3].text.strip()       # 4ta columna\n",
    "        last_action_date = cells[4].text.strip()  # 5ta columna\n",
    "        bill = (bill_id, description, chamber, last_action, last_action_date)\n",
    "        bills.append(bill)\n",
    "    return bills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mIndexError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[72]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Uncomment to test your code\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m test_url = \u001b[43msenate_members\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m      3\u001b[39m get_bills(test_url)[\u001b[32m0\u001b[39m:\u001b[32m5\u001b[39m]\n",
      "\u001b[31mIndexError\u001b[39m: list index out of range"
     ]
    }
   ],
   "source": [
    "# Uncomment to test your code\n",
    "test_url = senate_members[0][3]\n",
    "get_bills(test_url)[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scrape All Bills\n",
    "\n",
    "Finally, create a dictionary `bills_dict` which maps a district number (the key) onto a list of bills (the value) coming from that district. You can do this by looping over all of the senate members in `members_dict` and calling `get_bills()` for each of their associated bill URLs.\n",
    "\n",
    "**NOTE:** please call the function `time.sleep(1)` for each iteration of the loop, so that we don't destroy the state's web site."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explicaci√≥n del bloque del c√≥digo ##\n",
    "Se crea un diccionario vac√≠o `bills_dict` que almacenar√° como clave el n√∫mero de distrito y como valor la lista de `bills` correspondientes a ese distrito. Luego se itera sobre cada senador en `members_dict`.\n",
    "Para cada senador, se obtiene la URL de sus bills y se llama a la funci√≥n `get_bills(bill_url)`.\n",
    "Los resultados se almacenan en `bills_dict` bajo la clave correspondiente al distrito del senador.\n",
    "Se incluye `time.sleep(1)` en cada iteraci√≥n para evitar saturar el sitio web.  \n",
    "\n",
    "En este caso, como los datos de senadores no se extrajeron correctamente en pasos previos, `members_dict` est√° vac√≠o. Por ello, bills_dict tambi√©n resulta vac√≠o y al intentar acceder a una clave espec√≠fica `como bills_dict[52]` genera un `KeyError`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "# Crear un diccionario para almacenar los bills por distrito\n",
    "bills_dict = {}\n",
    "# Crear un diccionario a partir de la lista de miembros\n",
    "# La clave ser√° el distrito, el valor la tupla completa de informaci√≥n del senador\n",
    "members_dict = {member[1]: member for member in senate_members}\n",
    "\n",
    "# Verificar el diccionario\n",
    "print(list(members_dict.keys()))  # Primeros los distritos\n",
    "print(list(members_dict.values()))  # Primeros los senadores\n",
    "# Recorrer todos los senadores en members_dict\n",
    "for district, member_info in members_dict.items():\n",
    "    bill_url = member_info[3]  # Tomar la URL de Bills de cada senador\n",
    "    if bill_url:  # Verificar que exista URL\n",
    "        bills = get_bills(bill_url)  # Obtener los bills de ese senador\n",
    "        bills_dict[district] = bills\n",
    "    else:\n",
    "        bills_dict[district] = []  # Si no hay URL, dejar lista vac√≠a\n",
    "\n",
    "    time.sleep(1)  # Pausa de 1 segundo para no saturar el sitio\n",
    "\n",
    "# Verificar algunos resultados\n",
    "for district in list(bills_dict.keys())[:5]:\n",
    "    print(f\"Distrito {district}: {len(bills_dict[district])} bills\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "52",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[82]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Uncomment to test your code\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mbills_dict\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m52\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[31mKeyError\u001b[39m: 52"
     ]
    }
   ],
   "source": [
    "# Uncomment to test your code\n",
    "bills_dict[52]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
